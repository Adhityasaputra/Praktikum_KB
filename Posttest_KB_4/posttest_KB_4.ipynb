{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Corona_NLP_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1] # Target\n",
    "y = data.iloc[:,-1] # Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data pelatihan: 2658\n",
      "Jumlah data pengujian: 1140\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 70% data untuk pelatihan\n",
    "print(\"Jumlah data pelatihan:\", len(X_train))\n",
    "\n",
    "# 30% data untuk pengujian\n",
    "print(\"Jumlah data pengujian:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      UserName  ScreenName             Location     TweetAt  \\\n",
      "0            1    0.000000                  NYC  02-03-2020   \n",
      "1            2    0.000263          Seattle, WA  02-03-2020   \n",
      "2            3    0.000527                  NaN  02-03-2020   \n",
      "3            4    0.000790          Chicagoland  02-03-2020   \n",
      "4            5    0.001053  Melbourne, Victoria  03-03-2020   \n",
      "...        ...         ...                  ...         ...   \n",
      "3793      3794    0.998947            Israel ??  16-03-2020   \n",
      "3794      3795    0.999210       Farmington, NM  16-03-2020   \n",
      "3795      3796    0.999473        Haverford, PA  16-03-2020   \n",
      "3796      3797    0.999737                  NaN  16-03-2020   \n",
      "3797      3798    1.000000  Arlington, Virginia  16-03-2020   \n",
      "\n",
      "                                          OriginalTweet           Sentiment  \n",
      "0     TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n",
      "1     When I couldn't find hand sanitizer at Fred Me...            Positive  \n",
      "2     Find out how you can protect yourself and love...  Extremely Positive  \n",
      "3     #Panic buying hits #NewYork City as anxious sh...            Negative  \n",
      "4     #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  \n",
      "...                                                 ...                 ...  \n",
      "3793  Meanwhile In A Supermarket in Israel -- People...            Positive  \n",
      "3794  Did you panic buy a lot of non-perishable item...            Negative  \n",
      "3795  Asst Prof of Economics @cconces was on @NBCPhi...             Neutral  \n",
      "3796  Gov need to do somethings instead of biar je r...  Extremely Negative  \n",
      "3797  I and @ForestandPaper members are committed to...  Extremely Positive  \n",
      "\n",
      "[3798 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "data_copy_min_max_scaler = data.copy()  # Salin dataset terlebih dahulu\n",
    "\n",
    "# Pilih atribut yang ingin dinormalisasi \n",
    "attribute_to_normalize = 'ScreenName'\n",
    "\n",
    "# Inisialisasi Min-Max Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Ubah nilai atribut yang dipilih ke dalam bentuk matriks kolom dan lakukan normalisasi\n",
    "data_copy_min_max_scaler[[attribute_to_normalize]] = scaler.fit_transform(data_copy_min_max_scaler[[attribute_to_normalize]])\n",
    "\n",
    "# Tampilkan dataset setelah normalisasi\n",
    "print(data_copy_min_max_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      UserName  ScreenName             Location     TweetAt  \\\n",
      "0    -1.731595       44953                  NYC  02-03-2020   \n",
      "1    -1.730683       44954          Seattle, WA  02-03-2020   \n",
      "2    -1.729771       44955                  NaN  02-03-2020   \n",
      "3    -1.728859       44956          Chicagoland  02-03-2020   \n",
      "4    -1.727946       44957  Melbourne, Victoria  03-03-2020   \n",
      "...        ...         ...                  ...         ...   \n",
      "3793  1.727946       48746            Israel ??  16-03-2020   \n",
      "3794  1.728859       48747       Farmington, NM  16-03-2020   \n",
      "3795  1.729771       48748        Haverford, PA  16-03-2020   \n",
      "3796  1.730683       48749                  NaN  16-03-2020   \n",
      "3797  1.731595       48750  Arlington, Virginia  16-03-2020   \n",
      "\n",
      "                                          OriginalTweet           Sentiment  \n",
      "0     TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n",
      "1     When I couldn't find hand sanitizer at Fred Me...            Positive  \n",
      "2     Find out how you can protect yourself and love...  Extremely Positive  \n",
      "3     #Panic buying hits #NewYork City as anxious sh...            Negative  \n",
      "4     #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  \n",
      "...                                                 ...                 ...  \n",
      "3793  Meanwhile In A Supermarket in Israel -- People...            Positive  \n",
      "3794  Did you panic buy a lot of non-perishable item...            Negative  \n",
      "3795  Asst Prof of Economics @cconces was on @NBCPhi...             Neutral  \n",
      "3796  Gov need to do somethings instead of biar je r...  Extremely Negative  \n",
      "3797  I and @ForestandPaper members are committed to...  Extremely Positive  \n",
      "\n",
      "[3798 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Misalnya 'data' adalah DataFrame Anda\n",
    "data_copy_standard = data.copy()  # Salin dataset terlebih dahulu\n",
    "\n",
    "# Inisialisasi Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Pilih atribut yang ingin di-standarisasi \n",
    "attribute_to_standardize = 'UserName'\n",
    "\n",
    "# Standarisasi atribut yang dipilih\n",
    "data_copy_standard[[attribute_to_standardize]] = scaler.fit_transform(data_copy_standard[[attribute_to_standardize]])\n",
    "\n",
    "# Tampilkan dataset setelah standarisasi\n",
    "print(data_copy_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilai unik dalam kolom 'TweetAt':\n",
      "['02-03-2020' '03-03-2020' '04-03-2020' '05-03-2020' '06-03-2020'\n",
      " '07-03-2020' '08-03-2020' '09-03-2020' '10-03-2020' '11-03-2020'\n",
      " '12-03-2020' '13-03-2020' '14-03-2020' '15-03-2020' '16-03-2020']\n"
     ]
    }
   ],
   "source": [
    "#diluar modul menghapus nilai non numeric\n",
    "print(\"Nilai unik dalam kolom 'TweetAt':\")\n",
    "print(data['TweetAt'].unique())\n",
    "# Mengubah nilai non-numeric dalam kolom 'days_before' menjadi NaN\n",
    "data['TweetAt'] = pd.to_numeric(data['TweetAt'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilai unik dalam kolom 'TweetAt':\n",
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "print(\"Nilai unik dalam kolom 'TweetAt':\")\n",
    "print(data['TweetAt'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilai unik dalam kolom 'TweetAt':\n",
      "['TRENDING: New Yorkers encounter empty supermarket shelves (pictured, Wegmans in Brooklyn), sold-out online grocers (FoodKick, MaxDelivery) as #coronavirus-fearing shoppers stock up https://t.co/Gr76pcrLWh https://t.co/ivMKMsqdT1'\n",
      " \"When I couldn't find hand sanitizer at Fred Meyer, I turned to #Amazon. But $114.97 for a 2 pack of Purell??!!Check out how  #coronavirus concerns are driving up prices. https://t.co/ygbipBflMY\"\n",
      " 'Find out how you can protect yourself and loved ones from #coronavirus. ?'\n",
      " ...\n",
      " \"Asst Prof of Economics @cconces was on @NBCPhiladelphia talking about her recent research on coronavirus' impact on the economy. Watch it here (starting at :33): https://t.co/8tfYNoro5l\"\n",
      " \"Gov need to do somethings instead of biar je rakyat assume 'lockdown' ke or even worst. Harini semua supermarket crowded like hell. Lagi mudah virus tu tersebar ?? #COVID2019\"\n",
      " 'I and @ForestandPaper members are committed to the safety of our employees and our end-users. We are monitoring COVID-19. Rest assured that tissue manufacturers are continuing to produce and ship products.  https://t.co/qF6hclCAEq https://t.co/xyvbNsFeXA']\n"
     ]
    }
   ],
   "source": [
    "print(\"Nilai unik dalam kolom 'TweetAt':\")\n",
    "print(data['OriginalTweet'].unique())\n",
    "# Mengganti nilai 'Wednesday' menjadi 'Wed' dalam kolom 'day_of_week'\n",
    "data['OriginalTweet'] = data['OriginalTweet'].replace('TRENDING: New Yorkers encounter empty supermarket shelves (pictured, Wegmans in Brooklyn), sold-out ')\n",
    "data['OriginalTweet'] = data['OriginalTweet'].replace('Find out how you can protect yourself and loved ones from #coronavirus. ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilai unik dalam kolom 'TweetAt':\n",
      "['TRENDING: New Yorkers encounter empty supermarket shelves (pictured, Wegmans in Brooklyn), sold-out online grocers (FoodKick, MaxDelivery) as #coronavirus-fearing shoppers stock up https://t.co/Gr76pcrLWh https://t.co/ivMKMsqdT1'\n",
      " \"When I couldn't find hand sanitizer at Fred Meyer, I turned to #Amazon. But $114.97 for a 2 pack of Purell??!!Check out how  #coronavirus concerns are driving up prices. https://t.co/ygbipBflMY\"\n",
      " '#Panic buying hits #NewYork City as anxious shoppers stock up on food&amp;medical supplies after #healthcare worker in her 30s becomes #BigApple 1st confirmed #coronavirus patient OR a #Bloomberg staged event?\\r\\r\\n\\r\\r\\nhttps://t.co/IASiReGPC4\\r\\r\\n\\r\\r\\n#QAnon #QAnon2018 #QAnon2020 \\r\\r\\n#Election2020 #CDC https://t.co/29isZOewxu'\n",
      " ...\n",
      " \"Asst Prof of Economics @cconces was on @NBCPhiladelphia talking about her recent research on coronavirus' impact on the economy. Watch it here (starting at :33): https://t.co/8tfYNoro5l\"\n",
      " \"Gov need to do somethings instead of biar je rakyat assume 'lockdown' ke or even worst. Harini semua supermarket crowded like hell. Lagi mudah virus tu tersebar ?? #COVID2019\"\n",
      " 'I and @ForestandPaper members are committed to the safety of our employees and our end-users. We are monitoring COVID-19. Rest assured that tissue manufacturers are continuing to produce and ship products.  https://t.co/qF6hclCAEq https://t.co/xyvbNsFeXA']\n"
     ]
    }
   ],
   "source": [
    "print(\"Nilai unik dalam kolom 'TweetAt':\")\n",
    "print(data['OriginalTweet'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Record Yang memiliki nilai null: \n",
      "UserName            0\n",
      "ScreenName          0\n",
      "Location          834\n",
      "TweetAt          3798\n",
      "OriginalTweet       0\n",
      "Sentiment           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Jumlah Record Yang memiliki nilai null: \")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset setelah data cleaning:\n",
      "Jumlah Record Yang memiliki nilai null: \n",
      "UserName            0\n",
      "ScreenName          0\n",
      "Location          834\n",
      "TweetAt          3798\n",
      "OriginalTweet       0\n",
      "Sentiment           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Menentukan strategi untuk mengisi nilai null\n",
    "strategies = {\n",
    "    'UserName': data['UserName'].median(),\n",
    "    'ScreenName': data['ScreenName'].mean(),\n",
    "    'TweetAt': data['TweetAt'].mean(),\n",
    "    'Sentiment': data['Sentiment'].mode()[0]\n",
    "}\n",
    "# Mengisi nilai null sesuai dengan strategi\n",
    "data_cleaned = data.fillna(value=strategies)\n",
    "\n",
    "# Cetak dataset setelah data cleaning\n",
    "print(\"\\nDataset setelah data cleaning:\")\n",
    "\n",
    "print(\"Jumlah Record Yang memiliki nilai null: \")\n",
    "print(data_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data yang memiliki nilai duplikat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Data yang memiliki nilai duplikat\")\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3798 entries, 0 to 3797\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   UserName       3798 non-null   int64  \n",
      " 1   ScreenName     3798 non-null   int64  \n",
      " 2   Location       2964 non-null   object \n",
      " 3   TweetAt        0 non-null      float64\n",
      " 4   OriginalTweet  3798 non-null   object \n",
      " 5   Sentiment      3798 non-null   object \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 178.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned['UserName'] = data_cleaned['UserName'].astype(int)\n",
    "data_cleaned['ScreenName'] = data_cleaned['ScreenName'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3798 entries, 0 to 3797\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   UserName       3798 non-null   int32  \n",
      " 1   ScreenName     3798 non-null   int32  \n",
      " 2   Location       2964 non-null   object \n",
      " 3   TweetAt        0 non-null      float64\n",
      " 4   OriginalTweet  3798 non-null   object \n",
      " 5   Sentiment      3798 non-null   object \n",
      "dtypes: float64(1), int32(2), object(3)\n",
      "memory usage: 148.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adtsa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Extremely Negative</th>\n",
       "      <th>Sentiment_Extremely Positive</th>\n",
       "      <th>Sentiment_Negative</th>\n",
       "      <th>Sentiment_Neutral</th>\n",
       "      <th>Sentiment_Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44953</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44954</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>44955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44956</td>\n",
       "      <td>Chicagoland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>44957</td>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>44958</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Do you remember the last time you paid $2.99 a...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>44959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Voting in the age of #coronavirus = hand sanit...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>44960</td>\n",
       "      <td>Geneva, Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@DrTedros \"We cant stop #COVID19 without prot...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>44961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HI TWITTER! I am a pharmacist. I sell hand san...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>44962</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anyone been in a supermarket over the last few...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>44963</td>\n",
       "      <td>Boksburg, South Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Best quality couches at unbelievably low price...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>44964</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beware of counterfeits trying to sell fake mas...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>44965</td>\n",
       "      <td>USA, PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Panic food buying in Germany due to #coronavir...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>44966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Covid_19 Went to the Grocery Store, turns out...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>44967</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>While we were busy watching election returns a...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>44968</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#AirSewa \\r\\r\\n\\r\\r\\n@flyspicejet is not provi...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>44969</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What Precautionary measures have you all taken...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>44970</td>\n",
       "      <td>Toronto, Ontario</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When youre stockpiling food &amp;amp; other suppl...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>44971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>That's about a week from now. A bit optimistic...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>44972</td>\n",
       "      <td>Tallahassee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Studies show the #coronavirus like #COVID19 ca...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UserName  ScreenName                Location  TweetAt  \\\n",
       "0          1       44953                     NYC      NaN   \n",
       "1          2       44954             Seattle, WA      NaN   \n",
       "2          3       44955                     NaN      NaN   \n",
       "3          4       44956             Chicagoland      NaN   \n",
       "4          5       44957     Melbourne, Victoria      NaN   \n",
       "5          6       44958             Los Angeles      NaN   \n",
       "6          7       44959                     NaN      NaN   \n",
       "7          8       44960     Geneva, Switzerland      NaN   \n",
       "8          9       44961                     NaN      NaN   \n",
       "9         10       44962         Dublin, Ireland      NaN   \n",
       "10        11       44963  Boksburg, South Africa      NaN   \n",
       "11        12       44964               New Delhi      NaN   \n",
       "12        13       44965                 USA, PA      NaN   \n",
       "13        14       44966                     NaN      NaN   \n",
       "14        15       44967          Washington, DC      NaN   \n",
       "15        16       44968              Bengaluru       NaN   \n",
       "16        17       44969                  Mumbai      NaN   \n",
       "17        18       44970        Toronto, Ontario      NaN   \n",
       "18        19       44971                     NaN      NaN   \n",
       "19        20       44972             Tallahassee      NaN   \n",
       "\n",
       "                                        OriginalTweet           Sentiment  \\\n",
       "0   TRENDING: New Yorkers encounter empty supermar...  Extremely Negative   \n",
       "1   When I couldn't find hand sanitizer at Fred Me...            Positive   \n",
       "2   When I couldn't find hand sanitizer at Fred Me...  Extremely Positive   \n",
       "3   #Panic buying hits #NewYork City as anxious sh...            Negative   \n",
       "4   #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral   \n",
       "5   Do you remember the last time you paid $2.99 a...             Neutral   \n",
       "6   Voting in the age of #coronavirus = hand sanit...            Positive   \n",
       "7   @DrTedros \"We cant stop #COVID19 without prot...             Neutral   \n",
       "8   HI TWITTER! I am a pharmacist. I sell hand san...  Extremely Negative   \n",
       "9   Anyone been in a supermarket over the last few...  Extremely Positive   \n",
       "10  Best quality couches at unbelievably low price...            Positive   \n",
       "11  Beware of counterfeits trying to sell fake mas...  Extremely Negative   \n",
       "12  Panic food buying in Germany due to #coronavir...  Extremely Negative   \n",
       "13  #Covid_19 Went to the Grocery Store, turns out...  Extremely Positive   \n",
       "14  While we were busy watching election returns a...            Positive   \n",
       "15  #AirSewa \\r\\r\\n\\r\\r\\n@flyspicejet is not provi...  Extremely Negative   \n",
       "16  What Precautionary measures have you all taken...  Extremely Positive   \n",
       "17  When youre stockpiling food &amp; other suppl...             Neutral   \n",
       "18  That's about a week from now. A bit optimistic...            Positive   \n",
       "19  Studies show the #coronavirus like #COVID19 ca...  Extremely Positive   \n",
       "\n",
       "    Sentiment_Extremely Negative  Sentiment_Extremely Positive  \\\n",
       "0                            1.0                           0.0   \n",
       "1                            0.0                           0.0   \n",
       "2                            0.0                           1.0   \n",
       "3                            0.0                           0.0   \n",
       "4                            0.0                           0.0   \n",
       "5                            0.0                           0.0   \n",
       "6                            0.0                           0.0   \n",
       "7                            0.0                           0.0   \n",
       "8                            1.0                           0.0   \n",
       "9                            0.0                           1.0   \n",
       "10                           0.0                           0.0   \n",
       "11                           1.0                           0.0   \n",
       "12                           1.0                           0.0   \n",
       "13                           0.0                           1.0   \n",
       "14                           0.0                           0.0   \n",
       "15                           1.0                           0.0   \n",
       "16                           0.0                           1.0   \n",
       "17                           0.0                           0.0   \n",
       "18                           0.0                           0.0   \n",
       "19                           0.0                           1.0   \n",
       "\n",
       "    Sentiment_Negative  Sentiment_Neutral  Sentiment_Positive  \n",
       "0                  0.0                0.0                 0.0  \n",
       "1                  0.0                0.0                 1.0  \n",
       "2                  0.0                0.0                 0.0  \n",
       "3                  1.0                0.0                 0.0  \n",
       "4                  0.0                1.0                 0.0  \n",
       "5                  0.0                1.0                 0.0  \n",
       "6                  0.0                0.0                 1.0  \n",
       "7                  0.0                1.0                 0.0  \n",
       "8                  0.0                0.0                 0.0  \n",
       "9                  0.0                0.0                 0.0  \n",
       "10                 0.0                0.0                 1.0  \n",
       "11                 0.0                0.0                 0.0  \n",
       "12                 0.0                0.0                 0.0  \n",
       "13                 0.0                0.0                 0.0  \n",
       "14                 0.0                0.0                 1.0  \n",
       "15                 0.0                0.0                 0.0  \n",
       "16                 0.0                0.0                 0.0  \n",
       "17                 0.0                1.0                 0.0  \n",
       "18                 0.0                0.0                 1.0  \n",
       "19                 0.0                0.0                 0.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Menggunakan OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)  # 'sparse=False' menghasilkan array NumPy, 'drop='first'' menghasilkan kategori biner\n",
    "\n",
    "# Melakukan One-Hot Encoding pada kolom 'time'\n",
    "encoded_data = encoder.fit_transform(data_cleaned[['Sentiment']])\n",
    "\n",
    "# Membuat DataFrame baru dengan hasil encoding\n",
    "encoded_df = pd.DataFrame(encoded_data, columns= encoder.get_feature_names_out(['Sentiment']))\n",
    "\n",
    "# Menggabungkan hasil encoding dengan dataset asli\n",
    "data_encoded = pd.concat([data_cleaned, encoded_df], axis=1)\n",
    "\n",
    "# Menampilkan hasil\n",
    "data_encoded.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
